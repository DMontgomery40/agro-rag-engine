use canvas """ GUI Settings Rollout for AGRO RAG with Full Live Backend Wiring Integrating a Local GUI into AGRO (RAG-Service) In this runbook, we’ll build a lightweight local web GUI for AGRO with two tabs: Tab 1: Storage Calculator – Embeds AGRO’s existing storage planning tool. Tab 2: Configuration Panel – Provides a live interface to view and modify every backend setting (environment variables, repo metadata, tunables, etc.) on the fly. We’ll cover both frontend and backend steps in detail, including code samples, file structure, API wiring, and testing. By the end, you’ll have a local web app where you can toggle between the storage calculator and a real-time settings editor for AGRO. Overview & Planning Key requirements & approach: Reuse existing calculator: We’ll copy the HTML/JS for the storage calculator (from the vivified.dev site) and serve it locally in Tab 1. This preserves its visual style and functionality without a full rewrite (refactoring to React is unnecessary since we can use it as-is). Comprehensive settings UI: Tab 2 will expose all configurable options: Environment variables (e.g. HYDRATION_MODE, REPO, GEN_MODEL, QDRANT_URL, etc.) – basically anything you’d normally put in .env GitHub GitHub . Per-repo metadata from repos.json – repository paths, keywords, path boosts, layer bonuses GitHub . Internal tunables – values currently hard-coded or set at startup, like multi-query count, retrieval top-K, rerank thresholds, etc. (e.g. MQ_REWRITES, CONF_TOP1, CONF_AVG5, FINAL_K, topk_dense, topk_sparse). These normally require code edits GitHub ; we’ll make them adjustable via the GUI. Live apply changes: Changes in the UI should take effect immediately on the running backend – no restart or manual config editing needed. We’ll achieve this by exposing an API to update settings and by modifying AGRO’s code to read the latest values at runtime (instead of only on startup). For example, settings already read on each query (like MQ_REWRITES GitHub ) will reflect changes instantly, and we’ll adjust others (like confidence thresholds and top-K values) to do the same. Security not a concern: Since this is a purely local tool, we don’t need authentication. Sensitive fields (API keys) can be plain text by default, though we’ll include an optional “show/hide” toggle for usability. Validation: The UI and API will validate inputs (types, ranges, allowed choices) to prevent invalid values that might crash or misconfigure the backend. Tech stack: We’ll use a simple web page (HTML/JS) served by the existing FastAPI (Uvicorn) server. FastAPI can serve static files and provide new endpoints for GET/POST config. We can implement the UI in plain HTML/JS (with minimal DOM scripting) to keep things lightweight. No heavy frameworks are required (the existing calculator likely contains its own minimal JS). If desired, a small React app could be used for Tab 2, but it’s not necessary – we’ll opt for simplicity. Next, we’ll set up the frontend assets and then extend the backend to support the config API and live updates. Frontend Setup (GUI Tabs) 1. agro Structure for GUI Files Create a new directory (e.g. gui/ or static/) in the AGRO agro to hold the frontend files. We’ll place the calculator HTML and the new config UI here. For example: agro/ ├── serve_rag.py # FastAPI app (we will modify this) ├── ... (other backend files) ├── gui/ # New GUI front-end assets │ ├── index.html # Main GUI page containing both tabs │ ├── rag-calculator.html # Storage calculator HTML (copied from vivified site) │ ├── style.css # (Optional) CSS for styling the tabs and form │ └── app.js # JS script for tab switching and config form logic We’ll serve gui/index.html as the main interface. This page will have a tabbed layout: one tab embedding rag-calculator.html and another containing the config form. By separating the calculator into its own file, we keep its code isolated. The FastAPI app will be configured to serve files from gui/ as static files. 2. Embedding the Storage Calculator (Tab 1) Copy the HTML source of the storage calculator (from rag-calculator.html in the vivi-site repo) into our agro as gui/rag-calculator.html. This file contains the interactive estimator for RAG storage. It likely includes its own styling and JavaScript. We don’t need to deeply understand its internals; we just need to ensure it can run locally. Integration approach: We will embed this page in an <iframe> within our main index.html (Tab 1 content area). Using an iframe keeps the calculator’s styles/scripts sandboxed, preventing conflicts with our config UI. Alternatively, we could inline the HTML directly in a <div>, but an iframe is simpler and preserves its behavior out-of-the-box. Make sure any referenced assets (CSS or JS files) in rag-calculator.html are either embedded or available. If the calculator references external URLs (e.g. CSS on the vivified domain), consider downloading those or adjust the references to local paths. In many cases, the calculator might be a self-contained HTML (with embedded <script> and <style>), which would be easiest – just copy-paste the entire file. Example snippet from index.html for Tab navigation and embedding the calculator: <!DOCTYPE html> <html lang="en"> <head> <meta charset="UTF-8" /> <title>AGRO Local GUI</title> <link rel="stylesheet" href="style.css" /> </head> <body> <!-- Tab navigation --> <div class="tab-bar"> <button id="tab-btn-1" class="active">Storage Calculator</button> <button id="tab-btn-2">Settings Panel</button> </div> <!-- Tab content: Tab 1 --> <div id="tab-content-1" class="tab-content active"> <!-- Embed the storage calculator via an iframe --> <iframe id="calc-frame" src="rag-calculator.html" style="width:100%; height: 100%; border:none;"> </iframe> </div> <!-- Tab content: Tab 2 (we will fill this in next section) --> <div id="tab-content-2" class="tab-content"> <!-- Settings form will be inserted here --> </div> <script src="app.js"></script> </body> </html> In the above: We define two buttons in a simple tab bar. Clicking these will show/hide the corresponding content divs. Tab 1 content: an <iframe> loads rag-calculator.html (which we will have sitting in the same gui/ folder). We give it full width/height so the calculator fills the area. Adjust the height style as needed (e.g. a fixed 600px or use viewport height). Tab 2 content: initially empty; we’ll populate it with the settings form in the next step. We include a style.css (for basic styling of tabs) and app.js (for tab switching and form logic). Styling Tabs (style.css): Add some basic styles for the tab bar and content: /* style.css */ body { margin: 0; font-family: sans-serif; } .tab-bar { background: #333; padding: 0.5em; } .tab-bar button { color: #fff; background: #444; border: none; padding: 0.5em 1em; cursor: pointer; margin-right: 0.2em; } .tab-bar button.active { background: #2277AA; } .tab-content { display: none; padding: 1em; } .tab-content.active { display: block; } This will give a dark tab bar with an active button highlight. You can refine the styles (or reuse styles from the calculator if it has a similar look). The .tab-content sections are hidden by default, and the active one is shown. Tab switching logic (app.js): We’ll add a small script to handle tab button clicks: // app.js (initial portion for tab switching) document.getElementById('tab-btn-1').addEventListener('click', () => { switchTab(1); }); document.getElementById('tab-btn-2').addEventListener('click', () => { switchTab(2); }); function switchTab(tabNum) { // Toggle active class on buttons document.getElementById('tab-btn-1').classList.toggle('active', tabNum === 1); document.getElementById('tab-btn-2').classList.toggle('active', tabNum === 2); // Show/hide content document.getElementById('tab-content-1').classList.toggle('active', tabNum === 1); document.getElementById('tab-content-2').classList.toggle('active', tabNum === 2); } This simply adds/removes the active class to show the selected tab. Now we have a working tab interface. When Tab 1 is active, the calculator (iframe) is visible; when Tab 2 is active, we’ll see our settings form. 3. Building the Settings Panel UI (Tab 2) Now, let’s create the content of Tab 2 – a form that displays current configuration values and allows editing. We will group settings into logical sections for clarity. Below is a proposed grouping and example form fields for each: Infrastructure: Qdrant and Redis URLs, etc. Repo Selection: Active repo name (and possibly default repo). Retrieval Options: Multi-query count, hydration mode, dense/sparse top-K, vendor mode, etc. Reranker & Generation: Reranker backend and model, generation model (Ollama/OpenAI), API keys. Embeddings: Embedding provider type and API keys. Other: Netlify settings, LangChain flags, etc. Per-Repo Metadata: A subsection to edit repos (path, keywords, boosts, etc.). We will fetch the current values from the backend via a GET request (e.g. GET /api/config). The backend will supply all the values (from environment and repos.json) as JSON. Then we populate the form fields. The user can modify and click “Apply” (or “Save”) to submit changes via POST. HTML Form Structure: Inside the tab-content-2 div in index.html, add a form (or just a container with inputs and a button). For example: <!-- Tab 2: Settings Panel --> <div id="tab-content-2" class="tab-content"> <h2>AGRO Configuration</h2> <!-- Environment/Settings form --> <form id="config-form"> <!-- Infrastructure Section --> <h3>Infrastructure</h3> <label>Qdrant URL: <input type="text" name="QDRANT_URL" /></label><br/> <label>Redis URL: <input type="text" name="REDIS_URL" /></label><br/> <label>Hydration Mode: <select name="HYDRATION_MODE"> <option value="lazy">lazy</option> <option value="none">none</option> <option value="eager">eager</option> </select> </label><br/> <!-- Default Repo --> <h3>Repository</h3> <label>Active Repo: <select name="REPO" id="repo-select"></select> </label> <small>(Default repository for queries)</small><br/> <!-- We will populate the repo options dynamically from repos.json --> <!-- Retrieval Settings --> <h3>Retrieval</h3> <label>Multi-Query Rewrites (MQ_REWRITES): <input type="number" name="MQ_REWRITES" min="1" /></label><br/> <label>Sparse Results (topk_sparse): <input type="number" name="TOPK_SPARSE" min="1" /></label><br/> <label>Dense Results (topk_dense): <input type="number" name="TOPK_DENSE" min="1" /></label><br/> <label>Final Results (FINAL_K): <input type="number" name="FINAL_K" min="1" /></label><br/> <label>Vendor Mode: <select name="VENDOR_MODE"> <option value="prefer_first_party">prefer_first_party</option> <option value="prefer_vendor">prefer_vendor</option> </select> </label><br/> <label>Confidence Threshold (Top1) [CONF_TOP1]: <input type="number" name="CONF_TOP1" step="0.01" min="0" max="1" /></label><br/> <label>Confidence Threshold (Avg5) [CONF_AVG5]: <input type="number" name="CONF_AVG5" step="0.01" min="0" max="1" /></label><br/> <!-- Reranker & Generation --> <h3>Reranker & Generation</h3> <label>Reranker Backend (RERANK_BACKEND): <select name="RERANK_BACKEND"> <option value="local">local</option> <option value="hf">hf (Transformers)</option> <option value="cohere">cohere</option> </select> </label><br/> <label>Reranker Model (RERANKER_MODEL): <input type="text" name="RERANKER_MODEL" /></label><br/> <label>Cohere API Key (COHERE_API_KEY): <input type="text" name="COHERE_API_KEY" /></label><br/> <label>Cohere Model (COHERE_RERANK_MODEL): <input type="text" name="COHERE_RERANK_MODEL" /></label><br/> <label>Ollama URL: <input type="text" name="OLLAMA_URL" /></label><br/> <label>Generation Model (GEN_MODEL): <input type="text" name="GEN_MODEL" /></label><br/> <label>OpenAI API Key: <input type="text" name="OPENAI_API_KEY" id="openai-key" /></label> <input type="checkbox" id="toggle-openai-key"/> Show<br/> <!-- Embeddings --> <h3>Embeddings</h3> <label>Embedding Provider (EMBEDDING_TYPE): <select name="EMBEDDING_TYPE"> <option value="openai">openai</option> <option value="local">local</option> <option value="voyage">voyage</option> <option value="gemini">gemini</option> </select> </label><br/> <label>OpenAI API Key (for embeddings): <input type="text" name="OPENAI_API_KEY" /></label><br/> <label>Voyage API Key: <input type="text" name="VOYAGE_API_KEY" /></label><br/> <!-- Other Settings --> <h3>Miscellaneous</h3> <label>Netlify Domains (NETLIFY_DOMAINS): <input type="text" name="NETLIFY_DOMAINS" /></label><br/> <label>Netlify API Key: <input type="text" name="NETLIFY_API_KEY" /></label><br/> <label>LangChain Tracing V2 (LANGCHAIN_TRACING_V2): <input type="checkbox" name="LANGCHAIN_TRACING_V2"></label><br/> <label>LangChain agro (LANGCHAIN_agro): <input type="text" name="LANGCHAIN_agro" /></label><br/> <!-- Repos Metadata Section --> <h3>Repositories</h3> <div id="repos-section"> <!-- We will dynamically generate fields for each repo here --> </div> <!-- Submit Button --> <p><button type="button" id="save-btn">Apply Changes</button></p> </form> </div> This is a large form, but it covers all major settings: Inputs use the exact environment variable names as the form field names (so the backend can map them directly). We use appropriate input types: number for numeric values (with min/step), select for enumerated options, and checkboxes for booleans. Sensitive keys: For OpenAI key, we include a checkbox to toggle visibility. Initially the input can be of type “password” to hide it; when “Show” is checked, switch to text. (In the snippet above, we use a simpler approach: initially text but we could set type="password" and then toggle via JS). Repo selection: A dropdown for REPO will list all repo names from repos.json. We’ll fill #repo-select options via script. Repos metadata: We leave an empty <div id="repos-section">. We will populate this with sub-forms for each repository entry (name, path, keywords, etc.) using the data from repos.json. Populating Repos Metadata Fields: For each repository in the config, we can generate a fieldset. For example, if repos.json has: { "default_repo": "repo-a", "repos": [ { "name": "repo-a", "path": "/path/to/repo-a", "keywords": ["auth","backend"], "path_boosts": ["src/server/","api/"], "layer_bonuses": {"server": {"kernel": 0.10, "ui": 0.0}} }, ... ] } We’ll create inputs to edit those values. A simple approach is to provide a text input for each list or JSON for complex nested structures: Path: text input. Keywords: a text input (comma-separated list). Path boosts: text input (comma-separated paths). Layer bonuses: perhaps a textarea containing JSON. Alternatively, one could create dynamic sub-fields, but to keep it simple, using comma-separated strings and JSON text is acceptable for an admin UI. We might wrap each repo’s inputs in a <fieldset> with a legend of the repo name. Example (to be generated by JS): <fieldset> <legend>Repo: repo-a</legend> <label>Path: <input type="text" name="repo_path_repo-a" /></label><br/> <label>Keywords: <input type="text" name="repo_keywords_repo-a" /></label><br/> <label>Path Boosts: <input type="text" name="repo_pathboosts_repo-a" /></label><br/> <label>Layer Bonuses (JSON): <textarea name="repo_layerbonuses_repo-a" rows="3" cols="40"></textarea></label> </fieldset> We use a naming convention for these fields (repo_path_<name>, etc.) that the backend will interpret. For example, repo_path_repo-a corresponds to the path of repo “repo-a”. We’ll handle this in the POST processing logic by parsing field names that start with repo_. JS to Populate Form on Load: In app.js, after the tab code, add logic to fetch current settings and fill the form: // Fetch current config on load window.addEventListener('DOMContentLoaded', () => { fetch('/api/config') .then(res => res.json()) .then(data => { populateForm(data); }) .catch(err => console.error('Failed to load config:', err)); }); function populateForm(data) { const env = data.env || {}; const repos = data.repos || []; const defaultRepo = data.default_repo; // Fill env variables for (const [key, value] of Object.entries(env)) { let field = document.querySelector([name="${key}"]); if (!field) continue; if (field.type === 'checkbox') { // Boolean flags field.checked = (value === true || value === 'true'); } else { field.value = value != null ? value : ''; } } // Populate repo dropdown const repoSelect = document.getElementById('repo-select'); repoSelect.innerHTML = ''; for (const repo of repos) { const opt = document.createElement('option'); opt.value = repo.name; opt.textContent = repo.name; repoSelect.appendChild(opt); } if (env.REPO) { repoSelect.value = env.REPO; } else if (defaultRepo) { repoSelect.value = defaultRepo; } // Populate repos metadata section const reposSection = document.getElementById('repos-section'); reposSection.innerHTML = ''; repos.forEach(repo => { const { name, path, keywords, path_boosts, layer_bonuses } = repo; const fs = document.createElement('fieldset'); const legend = document.createElement('legend'); legend.textContent = Repo: ${name}; fs.appendChild(legend); // Path field fs.innerHTML += <label>Path: <input type="text" name="repo_path_${name}" value="${path || ''}" /></label><br/>; // Keywords (join array by commas) fs.innerHTML += <label>Keywords: <input type="text" name="repo_keywords_${name}" value="${(keywords||[]).join(',')}" /></label><br/>; // Path boosts fs.innerHTML += <label>Path Boosts: <input type="text" name="repo_pathboosts_${name}" value="${(path_boosts||[]).join(',')}" /></label><br/>; // Layer bonuses (JSON string) fs.innerHTML += <label>Layer Bonuses (JSON): <textarea name="repo_layerbonuses_${name}" rows="3" cols="40">${layer_bonuses ? JSON.stringify(layer_bonuses) : ''}</textarea> </label><br/>; reposSection.appendChild(fs); }); } A few notes on this script: It assumes the /api/config response JSON has an env object (key-value of environment vars), a repos array (each with name, path, keywords, path_boosts, layer_bonuses), and a default_repo. It fills each input named for an env var with the current value. Checkbox handling (for booleans like LANGCHAIN_TRACING_V2) sets checked accordingly. It builds the repo <select> options from the repo list. It then selects the current active repo (env.REPO if set, otherwise the default repo). It generates the repo fieldsets in the repos-section div. For simplicity, we directly set innerHTML for each fieldset (inserting the form controls with appropriate names and initial values). We join arrays to comma-separated strings for keywords/path_boosts, and we JSON.stringify the layer_bonuses object to put in the textarea. Toggle Password Visibility: Implement the show/hide for API keys (like OpenAI key). In app.js, add something like: document.getElementById('toggle-openai-key').addEventListener('change', function() { const openaiField = document.getElementById('openai-key'); openaiField.type = this.checked ? 'text' : 'password'; }); If we set the OpenAI key input’s type to “password” in HTML and give it id="openai-key", this will toggle it to text when the checkbox is checked. 4. Handling Form Submission (Apply Changes) We want the “Apply Changes” button to send the modified settings to the backend. We’ll do this via a POST XHR/fetch to our config API. We will gather all form data and package it into JSON. Add to app.js: document.getElementById('save-btn').addEventListener('click', () => { const form = document.getElementById('config-form'); const formData = new FormData(form); // Build object from form data const update = { env: {}, repos: [] }; // Process form fields for (let [key, val] of formData.entries()) { if (key.startsWith('repo_')) { // Repo-specific field // Format: repo_<field>_<reponame>, e.g. repo_path_repo-a const parts = key.split('_'); const field = parts[1]; // e.g. 'path' or 'keywords' or 'layerbonuses' const repoName = parts.slice(2).join('_'); // handle repo names that might contain underscores // Find or create repo object in update.repos let repoObj = update.repos.find(r => r.name === repoName); if (!repoObj) { repoObj = { name: repoName }; update.repos.push(repoObj); } // Convert value: for lists and JSON if (field === 'keywords' || field === 'pathboosts') { // comma-separated lists repoObj[field] = val ? val.split(',').map(s => s.trim()).filter(s => s) : []; } else if (field === 'layerbonuses') { try { repoObj['layer_bonuses'] = val ? JSON.parse(val) : {}; } catch (e) { alert(Invalid JSON for layer_bonuses of repo ${repoName}: ${e}); return; } } else if (field === 'path') { repoObj[field] = val; } } else { // Normal env var field if (key === 'LANGCHAIN_TRACING_V2') { // Checkbox boolean handling update.env[key] = formData.get(key) ? true : false; } else { update.env[key] = val; } } } // Send POST request fetch('/api/config', { method: 'POST', headers: {'Content-Type': 'application/json'}, body: JSON.stringify(update) }) .then(res => { if (!res.ok) throw new Error(Server responded with ${res.status}); return res.json(); }) .then(result => { if (result.status === 'success') { alert('Configuration updated successfully.'); } else { alert('Update failed: ' + (result.error || 'Unknown error')); } }) .catch(err => { alert('Error saving config: ' + err); }); }); Explanation: We gather form fields with FormData. We iterate over each entry. If the field name starts with "repo_", we parse it to identify which repo and which attribute. We accumulate these in update.repos array. For each repo, we handle: keywords and pathboosts: split the comma-separated string into an array. layerbonuses: parse the JSON. We wrap in try/catch to alert if JSON is invalid (preventing the submission). path: just assign string. Other fields go into update.env. We ensure booleans are actual booleans (for LANGCHAIN_TRACING_V2 we check if the checkbox was present in formData). Finally, we fetch('/api/config', {method: 'POST', ...}) with the JSON stringified body. We expect a JSON response with a status. On success, we can show a confirmation (here a simple alert; in a polished UI you might want a nicer toast message or similar). If an error is returned, show it. Validation note: We already handle JSON parse errors for layer bonuses. We might also consider validating numeric ranges (e.g. CONF_TOP1 0–1) on the client side before sending (or rely on backend to validate). Simplicity wise, backend will double-check too. That completes the front-end implementation. Now onto the backend. Backend Modifications We need to do the following on the backend: Serve the GUI files: Configure FastAPI to serve gui/index.html at some route (e.g. / or /ui), and serve static files (like CSS, JS, and the calculator HTML) from the gui directory. Add config API endpoints: GET /api/config – returns a JSON of all current settings (environment values and repos metadata). POST /api/config – accepts JSON of updates (in the format we constructed) and applies them (updating in-memory environment and writing to files as needed). Enable live-update of settings: This is critical. Many of AGRO’s settings are currently loaded at startup or hard-coded. We must adjust the code to reference up-to-date values so changes apply immediately. This involves: Using os.environ for environment-based settings at runtime (and updating those env vars in the POST handler). For static tunables (confidence thresholds, top-K, etc.), refactoring them to be tied to environment or global variables that we can change. Ensuring any cached objects (e.g. loaded models) are refreshed if needed when relevant config changes. Let’s go step-by-step. 1. Serving Static Files (GUI) In serve_rag.py (the FastAPI app for the RAG service), add a static files mount. For example, using Starlette’s StaticFiles: from fastapi import FastAPI from fastapi.responses import FileResponse, HTMLResponse from fastapi.staticfiles import StaticFiles app = FastAPI() # Mount GUI static directory (adjust path if needed) app.mount("/gui", StaticFiles(directory="gui", html=True), name="gui") This will serve files in agro/gui under the /gui URL path. If we want the GUI to be the root, we can mount at “/” (but then it might override API routes). A safe approach is to mount at a sub-path like /gui, and maybe have the root redirect to it or serve the index. Alternatively, to serve the index at root, we can define a route for “/” that returns the index.html content: @app.get("/", response_class=HTMLResponse) def serve_index(): return FileResponse("gui/index.html") And still mount static for other files: app.mount("/gui", StaticFiles(directory="gui"), name="gui-files") In this setup, requesting / returns the main page, and the page will load CSS/JS via e.g. <link href="gui/style.css"> if we adjust the paths accordingly. (In our index.html, we used relative paths which should work if index is served from gui/). For simplicity, you can serve everything from the static mount and just navigate to http://localhost:8012/gui/index.html. But nicer UX is root as index. Feel free to implement either. Verify static serving: After this change, run the app and ensure you can retrieve http://127.0.0.1:8012/gui/rag-calculator.html etc. Once working, proceed to API. 2. Config API Endpoints Add the following to serve_rag.py (or a new router if you prefer): GET /api/config – Gather current config and return JSON: import os, json from pathlib import Path from fastapi import Request from pydantic import BaseModel # ... inside serve_rag.py @app.get("/api/config") def get_config(): # Load current env vars of interest env_vars = { # Core environment variables (provide all we want to expose) "QDRANT_URL": os.getenv("QDRANT_URL", ""), "REDIS_URL": os.getenv("REDIS_URL", ""), "HYDRATION_MODE": os.getenv("HYDRATION_MODE", ""), "REPO": os.getenv("REPO", ""), "MQ_REWRITES": os.getenv("MQ_REWRITES", ""), "RERANK_BACKEND": os.getenv("RERANK_BACKEND", ""), "RERANKER_MODEL": os.getenv("RERANKER_MODEL", ""), "COHERE_API_KEY": os.getenv("COHERE_API_KEY", ""), "COHERE_RERANK_MODEL": os.getenv("COHERE_RERANK_MODEL", ""), "OLLAMA_URL": os.getenv("OLLAMA_URL", ""), "GEN_MODEL": os.getenv("GEN_MODEL", ""), "OPENAI_API_KEY": os.getenv("OPENAI_API_KEY", ""), "EMBEDDING_TYPE": os.getenv("EMBEDDING_TYPE", ""), "VOYAGE_API_KEY": os.getenv("VOYAGE_API_KEY", ""), "NETLIFY_DOMAINS": os.getenv("NETLIFY_DOMAINS", ""), "NETLIFY_API_KEY": os.getenv("NETLIFY_API_KEY", ""), "LANGCHAIN_TRACING_V2": os.getenv("LANGCHAIN_TRACING_V2", "false"), "LANGCHAIN_agro": os.getenv("LANGCHAIN_agro", ""), "VENDOR_MODE": os.getenv("VENDOR_MODE", ""), "CONF_TOP1": os.getenv("CONF_TOP1", ""), "CONF_AVG5": os.getenv("CONF_AVG5", ""), "FINAL_K": os.getenv("FINAL_K", ""), "TOPK_SPARSE": os.getenv("TOPK_SPARSE", ""), "TOPK_DENSE": os.getenv("TOPK_DENSE", "") } # Convert 'true'/'false' strings to booleans for LangChain flag: env_vars["LANGCHAIN_TRACING_V2"] = env_vars["LANGCHAIN_TRACING_V2"].lower() in ("1", "true", "yes") # Load repos.json repos_file = Path("repos.json") repo_data = {} if repos_file.exists(): try: repo_data = json.loads(repos_file.read_text()) except Exception as e: repo_data = {} else: # If no repos.json, attempt single-repo from env if env_vars["REPO"] and os.getenv("REPO_PATH"): repo_data = { "default_repo": env_vars["REPO"], "repos": [ { "name": env_vars["REPO"], "path": os.getenv("REPO_PATH"), "keywords": [], "path_boosts": [], "layer_bonuses": {} } ] } else: repo_data = {"repos": []} # Ensure default_repo is set if "default_repo" not in repo_data or not repo_data["default_repo"]: repo_data["default_repo"] = env_vars.get("REPO") or None return { "env": env_vars, "default_repo": repo_data.get("default_repo"), "repos": repo_data.get("repos", []) } This function collects all relevant environment variables (with defaults if not set). The list provided includes everything we exposed in the UI. It also tries to read repos.json to get the repo configurations. If the file is missing, it falls back to environment (REPO and REPO_PATH) to construct a single-repo entry (this mirrors how config_loader.py works GitHub ). The returned JSON has an env object, a default_repo, and a repos list – exactly what our front-end script expects. POST /api/config – Apply updates. This is more involved: We will receive JSON in the shape: {"env": {...}, "repos": [...]}. The handler should: Update environment variables (using os.environ) for each provided key in env. Also handle any special logic required when a certain env var changes (e.g., if switching models requires clearing a cache). Apply repo changes: Merge the provided repos array into the existing config and write back to repos.json. We should be careful not to lose any data. The simplest method is to load the current repos.json, then for each repo in the input, update its fields. If a repo path changes, we update it. If keywords or boosts change, update them. Finally, save the JSON. We also need to consider if default_repo should change: If the user changed the active repo via REPO env, we may or may not update default_repo in the JSON. It might make sense to set default_repo in repos.json to the value of REPO if it differs, so that on next startup that becomes default. Now, implement the endpoint: @app.post("/api/config") def update_config(request: Request): data = request.json() # since we expect JSON env_updates = data.get("env", {}) repos_updates = data.get("repos", []) # 1. Update environment variables for key, val in env_updates.items(): # Convert Python types to strings for os.environ (except booleans) if isinstance(val, bool): # e.g. LangChain flag os.environ[key] = "true" if val else "false" else: os.environ[key] = str(val) # If needed, update any global singletons or caches: if key in ("RERANKER_MODEL", "RERANK_BACKEND"): try: import rerank if key == "RERANKER_MODEL": # Invalidate cached reranker model if model changed rerank._RERANKER = None # No need to explicitly update rerank.RERANK_BACKEND because we will use os.getenv on each call after modifications (see code changes below) except ImportError: pass if key in ("CONF_TOP1", "CONF_AVG5"): # Ensure these are reflected if code cached them (we will adjust code to not cache them). pass # Similar handling for other keys if necessary... # (We will rely on our runtime-get adjustments mostly) # 2. Update repos.json repo_file = Path("repos.json") current_repos = {} if repo_file.exists(): try: current_repos = json.loads(repo_file.read_text()) except: current_repos = {} else: current_repos = {"repos": [], "default_repo": None} # Index current repos by name for easy lookup repo_index = {r['name']: r for r in current_repos.get("repos", [])} for ru in repos_updates: name = ru.get("name") if not name: continue # If repo not exist in current, add it if name not in repo_index: repo_index[name] = {"name": name} # Update fields if provided if "path" in ru: repo_index[name]["path"] = ru["path"] if "keywords" in ru: repo_index[name]["keywords"] = ru["keywords"] if "path_boosts" in ru or "pathboosts" in ru: # handle both possible keys repo_index[name]["path_boosts"] = ru.get("path_boosts") or ru.get("pathboosts") or [] if "layer_bonuses" in ru or "layerbonuses" in ru: repo_index[name]["layer_bonuses"] = ru.get("layer_bonuses") or ru.get("layerbonuses") or {} # Build updated list new_repos_list = list(repo_index.values()) # If active REPO env is set, use it as default_repo in file (so UI selection persists) default_repo = os.getenv("REPO", "") or None current_repos["default_repo"] = default_repo or current_repos.get("default_repo") current_repos["repos"] = new_repos_list try: repo_file.write_text(json.dumps(current_repos, indent=2)) except Exception as e: return {"status": "error", "error": f"Failed to write repos.json: {e}"} return {"status": "success"} A few points: We use request.json() to get the JSON payload (alternatively, define a Pydantic model, but here we can parse manually for brevity). We iterate env updates, set os.environ. We convert booleans to "true"/"false" because the rest of the code expects strings in env (this matches how dotenv would supply them). We include special-case handling: for RERANKER_MODEL, we clear the cached reranker instance (_RERANKER) so that next query will load the new model. For RERANK_BACKEND, since our plan is to always check os.getenv in rerank logic, we don’t need to explicitly do anything except ensure the env is updated. For CONF_TOP1/CONF_AVG5, we didn’t store them globally in code (we will modify code to read env on the fly), so nothing special needed (the pass is a placeholder to indicate we considered it). Repos updates: We read current repos.json (to not overwrite fields not provided). Then update each repo entry found in the input: We identify repos by name. Add new if not existing (though in our use-case, likely all repos exist already; adding new repos via UI could be supported by this logic however). Update path, keywords, etc. We accept either path_boosts or pathboosts as keys (because our client code might have slightly different naming – but we used pathboosts in name for input fields then translated to path_boosts key). After merging, rewrite the JSON file. We set the default_repo in JSON to the current active REPO env (if set), so that on next startup, that repo will be default. This way, if the user switched the default repo in UI, it persists. Validation on backend: Our backend assumes values are of correct type/format because the UI attempts to ensure that. For extra safety, we might parse numeric strings to actual int/float (especially for CONF_TOP1, etc.). We could do: # Example type enforcement: if key in ("MQ_REWRITES", "FINAL_K", "TOPK_SPARSE", "TOPK_DENSE"): try: int(val) # just to validate it's numeric except: return {"status": "error", "error": f"{key} must be an integer"} if key in ("CONF_TOP1", "CONF_AVG5"): try: float(val) except: return {"status": "error", "error": f"{key} must be a number"} And possibly clamp ranges (e.g., CONF_TOP1 0–1). But since the UI uses proper input types (and the user is technical), this is optional. You can add as needed. 3. Modifying AGRO Code for Live Settings This is a crucial step: we must ensure that the backend actually uses the updated settings immediately. Below are the changes to make in various files: a. Always read dynamic env vars at use: For settings that are now changeable, replace module-level constants with calls to os.getenv at the point of use. Key places: Multi-query count – in langgraph_app.py, retrieve_node currently does: mq = int(os.getenv('MQ_REWRITES','2')) if should_use_multi_query(q) else 1 GitHub . This is already dynamic (reads env each time). We should, however, update the default to '4' to match our .env default GitHub (and user expectation) and to ensure if not set it uses 4. So change to: mq = int(os.getenv('MQ_REWRITES', '4')) when multi-query applies. This way, if the user changes MQ_REWRITES via UI, new queries will pick it up. Confidence thresholds – in langgraph_app.py, route_after_retrieval uses hard-coded 0.62 and 0.55 GitHub . We will introduce env usage: At the top of langgraph_app.py, add: CONF_TOP1 = float(os.getenv('CONF_TOP1', '0.62')) CONF_AVG5 = float(os.getenv('CONF_AVG5', '0.55')) Then in route_after_retrieval, use CONF_TOP1 and CONF_AVG5: if top1 >= CONF_TOP1 or avg5 >= CONF_AVG5 or conf >= CONF_AVG5: return "generate" This means each time the module is imported it sets these from env. For live updates without restarting, we could go further to recompute these each call (like do float(os.getenv(...)) inside the function). But since our UI updates os.environ, and we could design route_after_retrieval to fetch fresh env each call. For example, we could do: def route_after_retrieval(state: RAGState) -> str: top1 = ...; avg5 = ...; conf = ... # dynamic fetch try: conf_top1 = float(os.getenv('CONF_TOP1', '0.62')) conf_avg5 = float(os.getenv('CONF_AVG5', '0.55')) except: conf_top1, conf_avg5 = 0.62, 0.55 if top1 >= conf_top1 or avg5 >= conf_avg5 or conf >= conf_avg5: return "generate" ... This ensures changes apply immediately. It adds minimal overhead. Implement this approach for accuracy. (Remove or ignore the earlier CONF_TOP1 = ... constants if doing this.) Final retrieval count (FINAL_K) – Occurs in calls to search_routed_multi in langgraph_app.py. Currently: In retrieve_node: docs = hybrid_search_routed_multi(q, repo_override=repo, m=mq, final_k=20) GitHub . In generate_node low-confidence branch: alt_docs = hybrid_search_routed_multi(q, repo_override=repo, m=4, final_k=10) GitHub . We want to use an env-configurable final_k. We can: Define a default FINAL_K = int(os.getenv('FINAL_K', '10')) at top (for the typical case). Use final_k = int(os.getenv('FINAL_K', '10')) in each call. Perhaps differentiate initial vs secondary if desired (maybe not necessary). Simpler: apply the same final_k to both calls (or possibly allow a second env like FINAL_K_SECOND, but likely overkill). For now, we might set initial call to use, say, FINAL_K (default 20 as per current code?), and second call maybe also FINAL_K or a fraction. To keep it simple, we can just use the same FINAL_K for both. Example change: final_k = int(os.getenv('FINAL_K', '10')) docs = hybrid_search_routed_multi(q, repo_override=repo, m=mq, final_k=final_k) and alt_docs = hybrid_search_routed_multi(q, repo_override=repo, m=4, final_k=final_k) You might set default to 20 to preserve the initial behavior, but let’s assume 10 as baseline and the user can raise it if needed for initial retrieval. Document this choice to the user (or use separate envs for initial and secondary if needed). BM25/Vector top-K (topk_sparse, topk_dense) – In hybrid_search.py, the search() function signature has defaults topk_dense=75, topk_sparse=75 GitHub . These are not tied to env currently. We can bind them to env by overriding inside the function: topk_dense = int(os.getenv('TOPK_DENSE', '75')) topk_sparse = int(os.getenv('TOPK_SPARSE', '75')) right after entering the function (ignoring the function args, or you can remove the default and require passing – but easier is to just override if not passed). Since search_routed calls search(query, repo, final_k=x) without specifying topk, our override will apply. Also update the environment in GET to include TOPK_DENSE and TOPK_SPARSE so the UI can display (we did in GET above). Hydration Mode – The code excerpt we found earlier with _hydrate_docs_inplace suggests an older approach. In the current hybrid_search.py, hydration is done unconditionally via _load_code_cache. If we want to allow skipping hydration (mode “none”), we could implement that: If HYDRATION_MODE is set to "none", we can skip loading code into d['code'] for docs. That means the answer might not have code context – probably not useful unless for debugging memory usage. But since the user explicitly listed HYDRATION_MODE, we should honor it. Implement by checking env in the hydration loop. For example: hydration_mode = (os.getenv('HYDRATION_MODE', 'lazy') or 'lazy').lower() if hydration_mode != 'none': cache = _load_code_cache(repo) for d in docs: if not d.get('code'): ... d['code'] = cache['by_hash'].get(h) or ... or '' # If 'none', we leave 'code' empty (i.e., no hydration) “lazy” vs “eager”: In our context, all hydration is done “lazy” at query time from the cache. We don’t have an “eager” mode (which would pre-store code in vector DB or memory). We can treat any value other than "none" as "lazy" (which is current behavior). So basically, skip the loop if HYDRATION_MODE == 'none'. Reranker Backend & Model – The rerank logic in rerank.py currently sets RERANK_BACKEND and DEFAULT_MODEL at import GitHub . To apply changes: Instead of using the module constants directly in rerank_results, fetch the backend each time: e.g. backend = (os.getenv('RERANK_BACKEND', 'local') or 'local').lower() if backend == 'cohere': ... (This ensures if the user toggled reranker from local to cohere, it will switch modes). Similarly, for the model: maybe call os.getenv('RERANKER_MODEL', default) at time of use. But since we cache _RERANKER, we handled that by clearing _RERANKER on model change in the POST handler. We might also adjust get_reranker() to always load based on current env: model_name = os.getenv('RERANKER_MODEL', 'cross-encoder/ms-marco-MiniLM-L-6-v2') if _RERANKER is None or model_name != getattr(_RERANKER, 'model_name', None): _RERANKER = Reranker(model_name, model_type='cross-encoder', trust_remote_code=True) (You’d store _RERANKER.model_name or so for comparison). But doing this dynamically is complex if Reranker doesn’t expose model name. Our simpler approach to flush _RERANKER on change should suffice. So main is to use os.getenv for backend branching. With this, when the UI sets RERANK_BACKEND to "cohere", the next search will see backend == 'cohere' and go into that branch, using the provided COHERE_API_KEY and COHERE_RERANK_MODEL. If switched back to "local", it will revert to local reranker usage. Generation Model – env_model.py has _DEFAULT_MODEL = os.getenv("GEN_MODEL", os.getenv("ENRICH_MODEL", "gpt-4o-mini")). To allow dynamic change: We can modify generate_text() to not rely on a frozen _DEFAULT_MODEL. For instance: mdl = model or os.getenv("GEN_MODEL", os.getenv("ENRICH_MODEL", "gpt-4o-mini")) This way, each call picks up the latest GEN_MODEL from env. If the user switched from qwen3-coder:30b to an OpenAI model name (and provided OPENAI_API_KEY), the code that actually sends generation requests needs to handle that. How does generate_text choose between local vs OpenAI? Likely env_model.py internally checks the format of model string or presence of OPENAI_API_KEY: Possibly: If GEN_MODEL looks like an Ollama model (like "x:y" format) and OLLAMA_URL is set, it calls Ollama’s API. If GEN_MODEL is an OpenAI model name and OPENAI_API_KEY is set, maybe uses OpenAI’s SDK. We need to confirm logic in env_model.py. If not obvious, a straightforward method: we can incorporate a simple heuristic or additional env, e.g. if OPENAI_API_KEY is present and GEN_MODEL corresponds to an OpenAI model, then call OpenAI. If not, call Ollama. The user likely knows to blank one when using the other. Because of time, we assume env_model.py already handles selection (perhaps via the Responses API or similar). By ensuring os.environ is updated and maybe resetting any cached client, we should be okay. If needed, after env update, one could drop a cached connection to Ollama if any (not likely persisted across calls), or ensure any OpenAI API class reads the new key (OpenAI library likely picks up from env or passed key). If using an in-house approach, ensure they read OPENAI_API_KEY fresh. Possibly adding: import openai openai.api_key = os.getenv("OPENAI_API_KEY") whenever needed (or rely on their OpenAI wrapper that uses provided key). Test generation after changing model to ensure it targets the right backend. Embedding changes – Already dynamic via env: hybrid_search._get_embedding uses EMBEDDING_TYPE each call GitHub . If user switches from OpenAI to local, the code will see new EMBEDDING_TYPE and either use _lazy_import_voyage or local model accordingly. It caches the local model in _local_embed_model. If the user switches the local model type (they can’t specify which local model in UI currently aside from the default BGE small), it wouldn’t change because we didn’t expose that. That’s fine. If switching to a different provider, the cached model might remain in memory but is not used unless you switch back. This is acceptable. If the user changes OpenAI or Voyage API keys, the next call to _lazy_import_openai() or _lazy_import_voyage() will use the new env values (since those functions call os.getenv each time). That seems fine. Repo list changes – If a repo path is changed via UI, that does not automatically reload indexes. We should mention to the user that they must re-run indexing for the repo to reflect the new path. (We do persist the change in repos.json so subsequent indexing uses it.) A potential improvement is to trigger index_repo.py from the backend, but that’s beyond scope (and potentially slow). We’ll document this in testing. Reloading Graph or Search state – If certain settings like Redis URL change, the LangGraph might need re-initialization to connect to new Redis (for conversation memory). In langgraph_app.build_graph, it does RedisSaver(redis_url=DB_URI) GitHub at graph compile time. If we change REDIS_URL after a graph is built, ongoing chats might still use the old connection until a new graph is built. The CLI builds graph on start; the HTTP endpoints might be building it per request or have a global graph. If using a global graph, you could force recompile. Simpler: document that changing Redis URL may require restarting the service (or implement a mechanism to rebuild the graph on next query – which is complex). Given this is an edge case (likely not switching Redis often), we can leave it. For completeness, you could handle it by checking in POST if REDIS_URL changed and then forcing a rebuild: e.g. in POST, if REDIS_URL changed, set a global flag or call langgraph_app.build_graph() again and store it. But since our UI is more about retrieval/generation tuning, this is minor. Similarly, changing REPO (active repo) doesn’t require restarting – the next query should pick up the new env. Actually, our route_repo in hybrid_search uses os.getenv('REPO','agro') as default GitHub , and Chat CLI passes the repo in state. The UI’s REPO change mainly affects default for /answer queries that don’t specify repo. If needed, one could adjust any global state for current repo. Probably not – just rely on env. Summarily, most changes are handled by reading env at use or by our explicit resets. Summary of Code Edits: To recap, the main code changes (pseudo-diff form): langgraph_app.py: Use os.getenv('MQ_REWRITES','4') in retrieve_node. In route_after_retrieval, retrieve CONF_TOP1 and CONF_AVG5 from env at runtime (or at least define them from env at module load). Use env-driven FINAL_K for calls to hybrid_search_routed_multi. hybrid_search.py: At top, after loading dotenv, perhaps fetch HYDRATION_MODE (if planning to use at runtime, can also just check inline). In search(), set topk_dense = int(os.getenv('TOPK_DENSE','75')) and same for sparse. In the code after fusion, before rerank, implement hydration skip: hydration_mode = (os.getenv('HYDRATION_MODE','lazy') or 'lazy').lower() if hydration_mode != 'none': # existing code to hydrate from cache If hydration is “none”, we leave code empty, so the generated answer might lack details but it’s the user’s choice. rerank.py: Inside rerank_results(), use backend = (os.getenv('RERANK_BACKEND','local') or 'local').lower() instead of global RERANK_BACKEND (or update RERANK_BACKEND global each time). Also use model_name = os.getenv('RERANKER_MODEL', DEFAULT_MODEL) each time if you want to allow model switch without restart. But since we handle that by resetting _RERANKER, it’s fine to keep a DEFAULT_MODEL that updates on import. If you want belt-and-suspenders, recompute it. Ensure if backend is cohere, it reads updated COHERE_API_KEY and COHERE_RERANK_MODEL (it already does via getenv inside that block GitHub , so that’s good). env_model.py: Use dynamic os.getenv("GEN_MODEL") in generate_text. Ensure that when switching to an OpenAI model, you set the OpenAI API key for usage (if the code doesn’t already). Possibly call openai.api_key = os.getenv("OPENAI_API_KEY") if using OpenAI’s lib. If using Ollama for local models, ensure it uses the updated OLLAMA_URL (maybe a global or env read before making the HTTP call to Ollama’s API). Implement these code changes in the respective files. Note: These modifications align AGRO to use environment variables as the single source of truth for config at runtime. After applying, any update to os.environ (which our POST handler does) will affect the very next query. 4. Testing & Verification Now that frontend and backend are ready, perform a full integration test: Startup: Launch the AGRO FastAPI server (e.g. uvicorn serve_rag:app --reload --host 127.0.0.1 --port 8012). Ensure it starts without errors. The console should show the static mount for /gui. Access GUI: Open a browser to http://127.0.0.1:8012/ (or /gui/index.html if that’s how you set it up). You should see the tab interface. Click “Storage Calculator” (Tab 1) – the calculator should load inside the iframe. Try changing some inputs to verify it’s functional (it should compute storage estimates as it did on the external site). Switch to “Settings Panel” (Tab 2). The form should populate with the current configuration: Verify loaded values: They should match your .env and repos.json. For example, if your .env had MQ_REWRITES=4, the field shows 4. If HYDRATION_MODE wasn’t set (default), it might show blank or “lazy”. Repo dropdown should list your repos (e.g., “repo-a”, “repo-b”…). Paths and keywords from repos.json should appear in their fields. Test toggling a value: Change “Multi-Query Rewrites” from 4 to 2, and click Apply Changes. You should get an “updated successfully” alert. Now, on the backend, this should have set os.environ["MQ_REWRITES"]="2". Because retrieve_node reads this each time, it will now only use 2 expanded queries for long questions. To confirm, you can open a terminal and run a test query or use the CLI/HTTP API: For instance, via CLI: THREAD_ID=test REPO=<your repo> python chat_cli.py, ask a complex question (“Explain how X works…”). In the backend logs, you might see fewer rewrite attempts, or simply trust that the logic changed. Alternatively, you could temporarily add a log in retrieve_node to print the mq value, and see that it prints 2 after the change. Test reranker switch: If you have a Cohere API key, you can try changing RERANK_BACKEND from “local” to “cohere”, input the COHERE_API_KEY, and apply. Then ask a question via the UI or CLI. The first search after switching will call the Cohere rerank API. Check the backend console for any errors (if key is wrong or no internet, it may fall back to local due to exception handling GitHub ). If successful, results are now reranked by Cohere’s model. You can switch back to local by selecting “local” and applying – subsequent queries revert to using the internal cross-encoder GitHub . Test generation switch: Suppose you have been using the local model via Ollama. Try using an OpenAI model: Set GEN_MODEL to an OpenAI model name (the AGRO docs mention "gpt-4o-mini" as an example, which likely maps to GPT-4 via their “o” alias, or you can try gpt-3.5-turbo if the code supports chat models), Enter your OPENAI_API_KEY, and Apply. Now ask a question. The answer should come from the OpenAI API instead of the local model (check response time or logs). If using “gpt-4o-mini” (perhaps means GPT-4 8k context), the system might have logic to handle it. If nothing happens or an error occurs, ensure env_model.py uses the key correctly. Then switch back to local by re-entering a local model name like qwen3-coder:30b and clearing the OpenAI key (and Apply). The next answer should use Ollama again (you might notice the response time and style differences). Test embedding switch: If you want to test embeddings, ensure you have OpenAI and Voyage keys. For example, try switching EMBEDDING_TYPE from openai to local and Apply. Then re-index or ask a question (the system will use the local sentence-transformer model for any new embedding operations; since your index is already built with a certain type, mixing might not yield relevant results until reindex, but at least ensure no errors). Switch to voyage with a Voyage API key, etc. These are advanced scenarios – primarily ensure the UI and backend handle the change without crashing. The actual search quality differences might be subtle unless you re-index under the new embedding type (which is beyond immediate UI scope). Test other fields: Toggle HYDRATION_MODE to “none” and Apply. Ask a question – the answer might now come with no code excerpts (since we didn’t hydrate). This tests the skip logic. Then revert to “lazy”, and the code context should appear again in answers. Try adjusting confidence thresholds: e.g., raise CONF_TOP1 to 1.0 and CONF_AVG5 to 1.0 (meaning require perfect confidence to generate an answer). Ask a question – likely the system will decide confidence is below 1.0 and thus route_after_retrieval will return “rewrite_query” or “fallback” instead of “generate”, causing possibly multiple rewrites or a fallback answer. This is a way to test that our threshold env is used. Then set them back to default (0.62/0.55) to restore normal behavior GitHub . Change Vendor Mode to “prefer_vendor” and Apply. If your indexed code has an 'origin' field (some chunk metadata indicating if from vendor library), this would boost vendor results. If not, you might not see an effect, but at least ensure no errors. (Check that origin_bonus logic reads os.environ properly – we made sure to use 'VENDOR_MODE' in os.environ in code so that if it’s set, it applies the bonus GitHub . Our POST sets the env, so it should pick up.) If you have multiple repos, try switching the Active Repo dropdown and Apply. This will update REPO env. Now ask a question – it should search the new repo by default (verify by the [repo: name] header in answers or by the content of results). The UI default_repo in repos.json is also updated to this, so on restart it remains default. Edit repos metadata: e.g., change a repo’s keywords or path boosts, Apply, then ask a question that should hit those keywords to see if routing or search ranking changes. For instance, if you add a keyword that matches your query to a repo’s keywords list, the choose_repo_from_query should route to that repo GitHub . Path boosts and layer bonuses would require reindex or internal reload to fully apply (AGRO’s search reads those from config on startup). Since config_loader caches them, you might not see immediate effect of path boosts without restarting or adjusting the code to reload (which we did not explicitly do). In practice, path boosts are applied in code via static tables or by reading env (we saw a agro_PATH_BOOSTS usage GitHub ). We did not incorporate dynamic reading of repos.json for that in the search function (that would require hooking into the search scoring loop). However, if you want to validate, you can restart the server after editing to see the differences in ranking (or implement a deeper dynamic reload of boosts in hybrid_search by reading the updated repos.json on each query – not done here for brevity). Regardless, verifying that repos.json file did get updated is important: open repos.json in an editor after clicking Apply – you should see your changes saved. Persistence: Stop and restart the backend, and refresh the UI. Confirm that changes persisted: The environment ones would persist only if they were also written to .env or if you run the UI again. We are not writing to the .env file (by design, we treat our UI changes as runtime overrides). On restart, .env is reloaded with original values, except for those we wrote to repos.json. So don’t be surprised if environment fields revert on restart. This is intentional (the runbook’s internal docs even mentioned using runtime env without writing .env GitHub ). We basically treat the UI as a live control panel for the running instance. Repos.json changes do persist (we saved the file). So repo paths, keywords etc. will remain updated across restarts. Active default repo is also updated in repos.json as default_repo, so it will persist too. If you want certain env changes to persist, you should update your .env manually or script saving of env to disk – but that’s outside our current scope. Final note: We have provided a complete step-by-step integration. The GUI gives a convenient alternative to editing .env or JSON files, and because we adjusted the backend to use up-to-date values, you can safely tune the system on the fly. Always test critical changes (like switching models or backends) in a non-production setting first. With this runbook, even a newcomer to the agro should be able to set up and use the GUI for AGRO’s RAG engine configuration. """ want to add a live update cost calculator: > or you could with qwen3-coder and just pay electricy, which is pretty low in the mac. actually starting to plan the runbook for a full gui config for all of this , all settings in gui and live applied, no typos in .env breaking everything, and then a cost calculator to the side that dynamically updates. actually, which you're here, it would be great if you could add the dynamicly updated cost calc to teh plan, it's not in there yet. and then i want to add profiles, super lightweight tool but very ux handy. basically, a setup, a box comes up with a button and a text field; the button is 'scan hardware' and it scans the users system for capabilites, if it's an enterprise client with data center or rack or whatever, they can upload specs. the field is budget. they put in a dollar amount. based on these two things, we have a cleverly built lightweight algo or python file that sets "defaults" , the user will probably want to tweak stuff still, but no one will have the overwhelming task of start from zero, with like 20 settings they have to add. OH and i just though of one more: there is NOTHING worse than having a full .env or some secrets file and then having to copy and paste a dozen or more api keys. to they can upload an .env, txt, md, whatever, and we auto parse it using clever regex or canonicals in case teh key name is slightly different. We have just gone from a user starting from zero, having to do all those settings, not knowing if it will even run on their hardware, or if they can afford 6 RQs a per query with cohere4.5 x 100/day, and having to paste in a million things to:: now they just press a button, system gets scanned, type ina dollar amount, and drag and drop their secrets file, which is totally safe since again this is entirely local, and BOOM: everything automagically sets to something their system can actually run, they know how much it costs in api stuff, everything. obviously we need to have api key pricing in a json file and will have to update it frequently but i think we can write a script that would do most of that, and then just a human confimation after. actually a chatgpt weekly task could do that research too... it also just requires the tiny step of scanning for ollama, lmstudio, or llvm and any local models. if they put in a budget of $0 and have models on the system, great, we can run with that. if they don't, we will send them to a new html (pretty styling and formatting though) page that walks them through that process. Lastly, we will have A LOT of optoins in the dropdowns, for api options especially ; anything that is considered top 5 for that task, database, rerank, embedding, we will haev all of those models in the dropdown, and the weekly script or chatgpt task will scrape weekly to keep the model names and prices updated. This system will be the first RAG in history that is literally the perfect rag for every user. And no confusing crap, it's all in one slick looking webpage. It's gonna be big.