"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[200],{7137:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>d,contentTitle:()=>a,default:()=>h,frontMatter:()=>t,metadata:()=>s,toc:()=>o});const s=JSON.parse('{"id":"configuration/alerting","title":"Alerting System","description":"AGRO\'s comprehensive alerting system catches incidents like orphaned loops before they cost hundreds of dollars. The system combines Prometheus for metrics, AlertManager for routing, and FastAPI webhooks for logging.","source":"@site/docs/configuration/alerting.md","sourceDirName":"configuration","slug":"/configuration/alerting","permalink":"/agro-rag-engine/configuration/alerting","draft":false,"unlisted":false,"editUrl":"https://github.com/DMontgomery40/agro-rag-engine/tree/main/website/docs/configuration/alerting.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4},"sidebar":"docs","previous":{"title":"Filtering & Exclusions","permalink":"/agro-rag-engine/configuration/filtering"},"next":{"title":"Contributing","permalink":"/agro-rag-engine/development/contributing"}}');var i=r(4848),l=r(8453);const t={sidebar_position:4},a="Alerting System",d={},o=[{value:"Overview",id:"overview",level:2},{value:"Alert Rules (Priority 0-3)",id:"alert-rules-priority-0-3",level:2},{value:"P0: Cost &amp; Token Burn (CRITICAL)",id:"p0-cost--token-burn-critical",level:3},{value:"P1: API Anomalies (WARNING)",id:"p1-api-anomalies-warning",level:3},{value:"P2: Budget &amp; Cost Control (INFO \u2192 CRITICAL)",id:"p2-budget--cost-control-info--critical",level:3},{value:"P3: Quality Metrics (INFO)",id:"p3-quality-metrics-info",level:3},{value:"Alert Lifecycle",id:"alert-lifecycle",level:2},{value:"Notification Routing",id:"notification-routing",level:2},{value:"Critical Alerts",id:"critical-alerts",level:3},{value:"Warning Alerts",id:"warning-alerts",level:3},{value:"Info Alerts",id:"info-alerts",level:3},{value:"Configuration Files",id:"configuration-files",level:2},{value:"<code>/infra/prometheus-alert-rules.yml</code>",id:"infraprometheus-alert-rulesyml",level:3},{value:"<code>/infra/alertmanager.yml</code>",id:"infraalertmanageryml",level:3},{value:"<code>/infra/docker-compose.yml</code>",id:"infradocker-composeyml",level:3},{value:"<code>/server/alerts.py</code>",id:"serveralertspy",level:3},{value:"Viewing Alerts",id:"viewing-alerts",level:2},{value:"1. Prometheus UI (Real-time)",id:"1-prometheus-ui-real-time",level:3},{value:"2. AlertManager UI",id:"2-alertmanager-ui",level:3},{value:"3. Alert Log File",id:"3-alert-log-file",level:3},{value:"4. Grafana Dashboard",id:"4-grafana-dashboard",level:3},{value:"Testing Alerts",id:"testing-alerts",level:2},{value:"Test 1: Trigger TokenBurnSpike Alert",id:"test-1-trigger-tokenburnspike-alert",level:3},{value:"Test 2: Check Alert Webhook",id:"test-2-check-alert-webhook",level:3},{value:"Test 3: View AlertManager Status",id:"test-3-view-alertmanager-status",level:3},{value:"Extending Alerts",id:"extending-alerts",level:2},{value:"Add a Slack Notification",id:"add-a-slack-notification",level:3},{value:"Add a PagerDuty Integration",id:"add-a-pagerduty-integration",level:3},{value:"Add a Custom Webhook",id:"add-a-custom-webhook",level:3},{value:"Baseline Metrics (For Tuning)",id:"baseline-metrics-for-tuning",level:2},{value:"Incident Response",id:"incident-response",level:2},{value:"If CostBurnSpike or TokenBurnSustained Fires:",id:"if-costburnspike-or-tokenburnsustained-fires",level:3},{value:"Common Alert Scenarios",id:"common-alert-scenarios",level:2},{value:"Scenario 1: CostBurnSpike",id:"scenario-1-costburnspike",level:3},{value:"Scenario 2: TokenBurnSustained",id:"scenario-2-tokenburnsustained",level:3},{value:"Scenario 3: RetrievalQualityDegraded",id:"scenario-3-retrievalqualitydegraded",level:3},{value:"Scenario 4: HighErrorRate",id:"scenario-4-higherrorrate",level:3},{value:"Advanced Configuration",id:"advanced-configuration",level:2},{value:"Custom Alert Rules",id:"custom-alert-rules",level:3},{value:"Silence Alerts Temporarily",id:"silence-alerts-temporarily",level:3},{value:"Alert Thresholds via Environment Variables",id:"alert-thresholds-via-environment-variables",level:3},{value:"Files Changed",id:"files-changed",level:2},{value:"Next Steps",id:"next-steps",level:2},{value:"Monitoring Best Practices",id:"monitoring-best-practices",level:2},{value:"1. Start with Defaults",id:"1-start-with-defaults",level:3},{value:"2. Tune Based on Real Data",id:"2-tune-based-on-real-data",level:3},{value:"3. Document Alert Actions",id:"3-document-alert-actions",level:3},{value:"4. Test Regularly",id:"4-test-regularly",level:3},{value:"5. Review Alert Logs",id:"5-review-alert-logs",level:3},{value:"Additional Resources",id:"additional-resources",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,l.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"alerting-system",children:"Alerting System"})}),"\n",(0,i.jsx)(n.p,{children:"AGRO's comprehensive alerting system catches incidents like orphaned loops before they cost hundreds of dollars. The system combines Prometheus for metrics, AlertManager for routing, and FastAPI webhooks for logging."}),"\n",(0,i.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"The alerting system was built to catch the exact pattern of an orphaned Claude shell that consumed 2k tokens/sec for 2+ days, costing $200-300."}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Components"}),":"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Prometheus"})," - Metrics collection & alert rule evaluation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"AlertManager"})," - Alert routing & deduplication"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"FastAPI Webhook"})," - Alert logging & external integration points"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"alert-rules-priority-0-3",children:"Alert Rules (Priority 0-3)"}),"\n",(0,i.jsx)(n.h3,{id:"p0-cost--token-burn-critical",children:"P0: Cost & Token Burn (CRITICAL)"}),"\n",(0,i.jsx)(n.p,{children:"These rules catch runaway processes and orphaned loops:"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Alert"}),(0,i.jsx)(n.th,{children:"Threshold"}),(0,i.jsx)(n.th,{children:"Fires After"}),(0,i.jsx)(n.th,{children:"What It Catches"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"CostBurnSpike"})}),(0,i.jsx)(n.td,{children:"> $0.10/hour"}),(0,i.jsx)(n.td,{children:"2 min"}),(0,i.jsx)(n.td,{children:"Runaway API calls, reranking all documents"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"TokenBurnSpike"})}),(0,i.jsx)(n.td,{children:"> 5,000 tokens/min"}),(0,i.jsx)(n.td,{children:"2 min"}),(0,i.jsx)(n.td,{children:"Rapid token consumption spikes"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"TokenBurnSustained"})}),(0,i.jsx)(n.td,{children:"> 2,000 tokens/min"}),(0,i.jsx)(n.td,{children:"15 min"}),(0,i.jsxs)(n.td,{children:[(0,i.jsx)(n.strong,{children:"Orphaned loop pattern"})," (catches the 2-day incident)"]})]})]})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Real-World Example"}),": The orphaned loop incident:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Called ",(0,i.jsx)(n.code,{children:"/api/chat"})," every 2 seconds"]}),"\n",(0,i.jsx)(n.li,{children:"Reranked 100-200 documents each call"}),"\n",(0,i.jsxs)(n.li,{children:["Each document ~175 tokens \u2192 ",(0,i.jsx)(n.strong,{children:"3,500 tokens/call"})]}),"\n",(0,i.jsxs)(n.li,{children:["Every 2 seconds \u2192 ",(0,i.jsx)(n.strong,{children:"2,000+ tokens/min"})]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"This alert would fire after 15 minutes"})," (orphaned loop ran 2+ DAYS)"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"p1-api-anomalies-warning",children:"P1: API Anomalies (WARNING)"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Alert"}),(0,i.jsx)(n.th,{children:"Threshold"}),(0,i.jsx)(n.th,{children:"What It Catches"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"EndpointCallFrequencyAnomaly"})}),(0,i.jsxs)(n.td,{children:[(0,i.jsx)(n.code,{children:"/api/chat"})," > 10/min"]}),(0,i.jsx)(n.td,{children:"Bot, infinite retry loop, load test"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"CohereRerankingSpike"})}),(0,i.jsx)(n.td,{children:"> 20 rerank calls/min"}),(0,i.jsx)(n.td,{children:"Reranking too many documents"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"HighErrorRate"})}),(0,i.jsx)(n.td,{children:"> 5% errors"}),(0,i.jsx)(n.td,{children:"Provider issues, network problems"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"CohereRateLimitExceeded"})}),(0,i.jsx)(n.td,{children:"> 5 rate limit errors"}),(0,i.jsx)(n.td,{children:"API quota hit"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"TimeoutErrorSpike"})}),(0,i.jsx)(n.td,{children:"> 10 timeouts/5min"}),(0,i.jsx)(n.td,{children:"Network/provider latency issues"})]})]})]}),"\n",(0,i.jsx)(n.h3,{id:"p2-budget--cost-control-info--critical",children:"P2: Budget & Cost Control (INFO \u2192 CRITICAL)"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Alert"}),(0,i.jsx)(n.th,{children:"Threshold"}),(0,i.jsx)(n.th,{children:"Action"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"MonthlyBudgetWarning"})}),(0,i.jsx)(n.td,{children:"> $5"}),(0,i.jsx)(n.td,{children:"Monitor spend trend"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"MonthlyBudgetCritical"})}),(0,i.jsx)(n.td,{children:"> $40 / $50 cap"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"URGENT: Disable features or increase budget"})})]})]})]}),"\n",(0,i.jsx)(n.h3,{id:"p3-quality-metrics-info",children:"P3: Quality Metrics (INFO)"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Alert"}),(0,i.jsx)(n.th,{children:"Threshold"}),(0,i.jsx)(n.th,{children:"What It Means"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"RetrievalQualityDegraded"})}),(0,i.jsx)(n.td,{children:"MRR < 0.6"}),(0,i.jsx)(n.td,{children:"Indexing may be stale"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"CanaryPassRateLow"})}),(0,i.jsx)(n.td,{children:"Pass rate < 90%"}),(0,i.jsx)(n.td,{children:"Quality regression detected"})]})]})]}),"\n",(0,i.jsx)(n.h2,{id:"alert-lifecycle",children:"Alert Lifecycle"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"Prometheus collects metrics (every 5s)\n         \u2193\nAlert rules evaluated (every 30s)\n         \u2193\nFiring alerts sent to AlertManager\n         \u2193\nAlertManager deduplicates & groups (10-60s)\n         \u2193\nRoutes to receivers (critical \u2192 warning \u2192 info)\n         \u2193\nWebhook sent to FastAPI \u2192 logged to data/logs/alerts.jsonl\n"})}),"\n",(0,i.jsx)(n.h2,{id:"notification-routing",children:"Notification Routing"}),"\n",(0,i.jsx)(n.h3,{id:"critical-alerts",children:"Critical Alerts"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"Severity: critical\n\u251c\u2500 Wait: 30s before sending\n\u251c\u2500 Repeat: every 1 hour\n\u2514\u2500 Route: /webhooks/alertmanager (logged)\n    [To add: Slack, PagerDuty, SMS]\n"})}),"\n",(0,i.jsx)(n.h3,{id:"warning-alerts",children:"Warning Alerts"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"Severity: warning\n\u251c\u2500 Wait: 1 min before sending\n\u251c\u2500 Repeat: every 4 hours\n\u2514\u2500 Route: /webhooks/alertmanager (logged)\n"})}),"\n",(0,i.jsx)(n.h3,{id:"info-alerts",children:"Info Alerts"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"Severity: info\n\u251c\u2500 Wait: 5 min before sending\n\u251c\u2500 Repeat: every 24 hours\n\u2514\u2500 Route: /webhooks/alertmanager (logged)\n"})}),"\n",(0,i.jsx)(n.h2,{id:"configuration-files",children:"Configuration Files"}),"\n",(0,i.jsx)(n.h3,{id:"infraprometheus-alert-rulesyml",children:(0,i.jsx)(n.code,{children:"/infra/prometheus-alert-rules.yml"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"20+ alert rules covering cost, tokens, errors, performance"}),"\n",(0,i.jsxs)(n.li,{children:["Organized into 2 groups: ",(0,i.jsx)(n.code,{children:"core_alerts"})," + ",(0,i.jsx)(n.code,{children:"cohere_monitoring"})]}),"\n",(0,i.jsx)(n.li,{children:"Ready-to-use thresholds based on typical AGRO usage"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"infraalertmanageryml",children:(0,i.jsx)(n.code,{children:"/infra/alertmanager.yml"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Alert routing rules (critical/warning/info)"}),"\n",(0,i.jsx)(n.li,{children:"Inhibition rules (silence warnings if critical is firing)"}),"\n",(0,i.jsxs)(n.li,{children:["Webhook receiver points to ",(0,i.jsx)(n.code,{children:"POST /webhooks/alertmanager"})]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"infradocker-composeyml",children:(0,i.jsx)(n.code,{children:"/infra/docker-compose.yml"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["New ",(0,i.jsx)(n.code,{children:"alertmanager"})," service (port 9093)"]}),"\n",(0,i.jsx)(n.li,{children:"Prometheus depends on AlertManager"}),"\n",(0,i.jsxs)(n.li,{children:["AlertManager stores state in volume ",(0,i.jsx)(n.code,{children:"alertmanager_data"})]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"serveralertspy",children:(0,i.jsx)(n.code,{children:"/server/alerts.py"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["FastAPI webhook receiver (",(0,i.jsx)(n.code,{children:"POST /webhooks/alertmanager"}),")"]}),"\n",(0,i.jsxs)(n.li,{children:["Logs all alerts to ",(0,i.jsx)(n.code,{children:"data/logs/alerts.jsonl"})]}),"\n",(0,i.jsxs)(n.li,{children:["Provides ",(0,i.jsx)(n.code,{children:"/webhooks/alertmanager/status"})," endpoint for audit"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"viewing-alerts",children:"Viewing Alerts"}),"\n",(0,i.jsx)(n.h3,{id:"1-prometheus-ui-real-time",children:"1. Prometheus UI (Real-time)"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# In browser: http://localhost:9090/alerts\n# Shows:\n# - Pending alerts (about to fire)\n# - Firing alerts (active)\n# - Alert rule evaluation status\n"})}),"\n",(0,i.jsx)(n.h3,{id:"2-alertmanager-ui",children:"2. AlertManager UI"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# In browser: http://localhost:9093\n# Shows:\n# - Active alerts\n# - Alert groups\n# - Silences & inhibitions\n# - Alert timeline\n"})}),"\n",(0,i.jsx)(n.h3,{id:"3-alert-log-file",children:"3. Alert Log File"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# All alerts logged to JSONL for analysis\ncat data/logs/alerts.jsonl | jq '.'\n\n# Find critical alerts\ncat data/logs/alerts.jsonl | jq 'select(.alert.labels.severity == \"critical\")'\n\n# Alert timeline\ncat data/logs/alerts.jsonl | jq '.timestamp, .alert.labels.alertname, .alert.labels.severity' | paste - - -\n"})}),"\n",(0,i.jsx)(n.h3,{id:"4-grafana-dashboard",children:"4. Grafana Dashboard"}),"\n",(0,i.jsx)(n.p,{children:"Can add alert status panels to existing dashboard (future work)."}),"\n",(0,i.jsx)(n.h2,{id:"testing-alerts",children:"Testing Alerts"}),"\n",(0,i.jsx)(n.h3,{id:"test-1-trigger-tokenburnspike-alert",children:"Test 1: Trigger TokenBurnSpike Alert"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Generate high token consumption\nfor i in {1..10}; do\n  curl -s \"http://localhost:8012/api/chat?query=test\" &\ndone\nwait\n\n# Check alerts fired\ncurl http://localhost:9090/api/v1/alerts?state=firing | jq '.data[] | .labels.alertname'\n"})}),"\n",(0,i.jsx)(n.h3,{id:"test-2-check-alert-webhook",children:"Test 2: Check Alert Webhook"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Trigger a test alert (create a Prometheus rule with 1s FOR clause)\n# Then verify it was logged:\n\ncurl http://localhost:8012/webhooks/alertmanager/status | jq '.recent_alerts[0]'\n"})}),"\n",(0,i.jsx)(n.h3,{id:"test-3-view-alertmanager-status",children:"Test 3: View AlertManager Status"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"curl http://localhost:9093/api/v1/alerts | jq '.[] | {alertname: .labels.alertname, status: .status, severity: .labels.severity}'\n"})}),"\n",(0,i.jsx)(n.h2,{id:"extending-alerts",children:"Extending Alerts"}),"\n",(0,i.jsx)(n.h3,{id:"add-a-slack-notification",children:"Add a Slack Notification"}),"\n",(0,i.jsxs)(n.p,{children:["Update ",(0,i.jsx)(n.code,{children:"/infra/alertmanager.yml"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"receivers:\n  - name: 'critical'\n    slack_configs:\n      - api_url: 'https://hooks.slack.com/services/YOUR/WEBHOOK/URL'\n        channel: '#alerts-critical'\n        title: 'AGRO Critical Alert'\n        text: '{{ .CommonAnnotations.description }}'\n"})}),"\n",(0,i.jsx)(n.h3,{id:"add-a-pagerduty-integration",children:"Add a PagerDuty Integration"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"receivers:\n  - name: 'critical'\n    pagerduty_configs:\n      - service_key: 'YOUR-SERVICE-KEY'\n        description: '{{ .GroupLabels.alertname }}'\n        client: 'AGRO'\n        details:\n          alert: '{{ .GroupLabels.alertname }}'\n          severity: '{{ .CommonLabels.severity }}'\n"})}),"\n",(0,i.jsx)(n.h3,{id:"add-a-custom-webhook",children:"Add a Custom Webhook"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"receivers:\n  - name: 'critical'\n    webhook_configs:\n      - url: 'https://your-notification-service.com/alerts'\n        send_resolved: true\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Then update ",(0,i.jsx)(n.code,{children:"/server/alerts.py"})," to call your custom integration."]}),"\n",(0,i.jsx)(n.h2,{id:"baseline-metrics-for-tuning",children:"Baseline Metrics (For Tuning)"}),"\n",(0,i.jsx)(n.p,{children:"Typical AGRO usage when healthy:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Requests/min"}),": 10-50 (mostly /api/search, /api/rerank)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Tokens/min"}),": 200-1000 (embeddings + LLM calls)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Cost/hour"}),": $0.01-$0.05 (mostly Cohere reranking)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Error rate"}),": < 0.5%"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Latency p99"}),": 1-3 seconds"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Cohere reranking calls/min"}),": 2-10"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"If your metrics differ significantly, alert thresholds may need adjustment."}),"\n",(0,i.jsx)(n.h2,{id:"incident-response",children:"Incident Response"}),"\n",(0,i.jsx)(n.h3,{id:"if-costburnspike-or-tokenburnsustained-fires",children:"If CostBurnSpike or TokenBurnSustained Fires:"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"1. Immediate: Check for orphaned processes"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'ps aux | grep -E "curl.*api/chat|python.*agro"\n\n# Kill if found\nkill -9 <PID>\n'})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"2. Check server logs"})," for repeated /api/chat calls"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"tail -f data/logs/queries.jsonl | jq 'select(.route == \"/api/chat\")'\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"3. Review Prometheus metrics"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Query cost burn rate\nrate(agro_cost_usd_total[5m]) * 3600\n\n# Query token burn rate\nrate(agro_tokens_total[5m]) * 60\n\n# Query API call frequency\nrate(agro_requests_total{route="/api/chat"}[5m])\n'})}),"\n",(0,i.jsxs)(n.p,{children:["Visit ",(0,i.jsx)(n.a,{href:"http://localhost:9090",children:"http://localhost:9090"})," and enter these queries."]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"4. Check environment variables"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'echo $COHERE_RERANK_TOP_N  # Should be <= 50\necho $RERANK_BACKEND       # Should not be "cohere" if disabled\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"5. Review recent changes"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"git log --oneline -20 | head -10\ngit diff HEAD~5..HEAD -- retrieval/rerank.py\n"})}),"\n",(0,i.jsx)(n.h2,{id:"common-alert-scenarios",children:"Common Alert Scenarios"}),"\n",(0,i.jsx)(n.h3,{id:"scenario-1-costburnspike",children:"Scenario 1: CostBurnSpike"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Symptoms"}),": Alert fires, cost jumping unexpectedly"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Common Causes"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Orphaned process calling API in tight loop"}),"\n",(0,i.jsx)(n.li,{children:"Misconfigured reranking (reranking all documents)"}),"\n",(0,i.jsxs)(n.li,{children:["Multi-query rewrites set too high (",(0,i.jsx)(n.code,{children:"MQ_REWRITES"}),")"]}),"\n",(0,i.jsx)(n.li,{children:"Expensive model accidentally selected"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Resolution"}),":"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Check for orphaned processes (see Incident Response)"}),"\n",(0,i.jsx)(n.li,{children:"Review recent config changes in GUI"}),"\n",(0,i.jsx)(n.li,{children:"Check Prometheus for spike timing"}),"\n",(0,i.jsx)(n.li,{children:"Roll back changes if identified"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"scenario-2-tokenburnsustained",children:"Scenario 2: TokenBurnSustained"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Symptoms"}),": Alert fires after 15+ minutes of high token usage"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Common Causes"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Background job stuck in loop"}),"\n",(0,i.jsxs)(n.li,{children:["Agent or script repeatedly calling ",(0,i.jsx)(n.code,{children:"/answer"})]}),"\n",(0,i.jsx)(n.li,{children:"Large batch processing job running"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Resolution"}),":"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Identify the source (check logs)"}),"\n",(0,i.jsx)(n.li,{children:"If intentional (batch job), silence the alert temporarily"}),"\n",(0,i.jsx)(n.li,{children:"If orphaned, kill the process"}),"\n",(0,i.jsx)(n.li,{children:"Consider rate limiting in reverse proxy"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"scenario-3-retrievalqualitydegraded",children:"Scenario 3: RetrievalQualityDegraded"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Symptoms"}),": MRR drops below 0.6"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Common Causes"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Index is stale (code changed but not re-indexed)"}),"\n",(0,i.jsx)(n.li,{children:"Wrong repository selected"}),"\n",(0,i.jsx)(n.li,{children:"Embedding model changed without re-indexing"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Resolution"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Re-index the repository\nREPO=agro python index_repo.py\n\n# Run evals to verify\npython -m eval.eval_loop --compare\n"})}),"\n",(0,i.jsx)(n.h3,{id:"scenario-4-higherrorrate",children:"Scenario 4: HighErrorRate"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Symptoms"}),": > 5% of requests failing"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Common Causes"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Provider API down (OpenAI, Cohere)"}),"\n",(0,i.jsx)(n.li,{children:"Network issues"}),"\n",(0,i.jsx)(n.li,{children:"Rate limits hit"}),"\n",(0,i.jsx)(n.li,{children:"Invalid API keys"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Resolution"}),":"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Check provider status pages"}),"\n",(0,i.jsxs)(n.li,{children:["Verify API keys in ",(0,i.jsx)(n.code,{children:".env"})]}),"\n",(0,i.jsx)(n.li,{children:"Check network connectivity"}),"\n",(0,i.jsx)(n.li,{children:"Review error logs for patterns"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"advanced-configuration",children:"Advanced Configuration"}),"\n",(0,i.jsx)(n.h3,{id:"custom-alert-rules",children:"Custom Alert Rules"}),"\n",(0,i.jsxs)(n.p,{children:["Add to ",(0,i.jsx)(n.code,{children:"/infra/prometheus-alert-rules.yml"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'groups:\n  - name: custom_alerts\n    rules:\n      - alert: HighLatency\n        expr: agro_retrieval_latency_seconds > 5\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: "Retrieval latency is high"\n          description: "Retrieval taking > 5s for {{ $value }}s"\n'})}),"\n",(0,i.jsx)(n.p,{children:"Then reload Prometheus:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"docker exec rag-prometheus kill -HUP 1\n"})}),"\n",(0,i.jsx)(n.h3,{id:"silence-alerts-temporarily",children:"Silence Alerts Temporarily"}),"\n",(0,i.jsxs)(n.p,{children:["Via AlertManager UI (",(0,i.jsx)(n.a,{href:"http://localhost:9093",children:"http://localhost:9093"}),"):"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:'Click "Silences"'}),"\n",(0,i.jsx)(n.li,{children:'Click "New Silence"'}),"\n",(0,i.jsxs)(n.li,{children:["Add matchers (e.g., ",(0,i.jsx)(n.code,{children:"alertname=TokenBurnSustained"}),")"]}),"\n",(0,i.jsx)(n.li,{children:"Set duration (e.g., 2 hours)"}),"\n",(0,i.jsx)(n.li,{children:"Add comment explaining why"}),"\n",(0,i.jsx)(n.li,{children:'Click "Create"'}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"alert-thresholds-via-environment-variables",children:"Alert Thresholds via Environment Variables"}),"\n",(0,i.jsx)(n.p,{children:"You can make thresholds configurable:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# In .env\nALERT_TOKEN_BURN_THRESHOLD=2000\nALERT_COST_BURN_THRESHOLD=0.10\n"})}),"\n",(0,i.jsx)(n.p,{children:"Then update Prometheus rules to use these (requires custom templating)."}),"\n",(0,i.jsx)(n.h2,{id:"files-changed",children:"Files Changed"}),"\n",(0,i.jsx)(n.p,{children:"When alerting was implemented, these files were modified:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"/infra/prometheus-alert-rules.yml"})," - New alert rules"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"/infra/alertmanager.yml"})," - New AlertManager config"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"/infra/docker-compose.yml"})," - Added AlertManager service"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"/infra/prometheus.yml"})," - Added rule_files and alerting config"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"/server/alerts.py"})," - New webhook receiver"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"/server/app.py"})," - Integrated alerts router"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Slack Integration"}),": Add Slack webhook to ",(0,i.jsx)(n.code,{children:"alertmanager.yml"})]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Email Alerts"}),": Configure SMTP in ",(0,i.jsx)(n.code,{children:"alertmanager.yml"})]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Custom Dashboard"}),": Add alert status panels to Grafana"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Alert Tuning"}),": Monitor baseline metrics for a few days, adjust thresholds"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Runbook Links"}),": Update alert annotations with runbook URLs"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Post-incident Review"}),": Document what alerts should have fired for past incidents"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"monitoring-best-practices",children:"Monitoring Best Practices"}),"\n",(0,i.jsx)(n.h3,{id:"1-start-with-defaults",children:"1. Start with Defaults"}),"\n",(0,i.jsx)(n.p,{children:"Don't over-customize initially. Run with defaults for 1-2 weeks to establish baselines."}),"\n",(0,i.jsx)(n.h3,{id:"2-tune-based-on-real-data",children:"2. Tune Based on Real Data"}),"\n",(0,i.jsx)(n.p,{children:"After baseline period, adjust thresholds based on actual usage patterns."}),"\n",(0,i.jsx)(n.h3,{id:"3-document-alert-actions",children:"3. Document Alert Actions"}),"\n",(0,i.jsx)(n.p,{children:"For each alert, document:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"What it means"}),"\n",(0,i.jsx)(n.li,{children:"How to investigate"}),"\n",(0,i.jsx)(n.li,{children:"Common causes"}),"\n",(0,i.jsx)(n.li,{children:"Resolution steps"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"4-test-regularly",children:"4. Test Regularly"}),"\n",(0,i.jsx)(n.p,{children:"Run test scenarios monthly to verify alerts still fire:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Monthly alert test\nbash scripts/test_alerts.sh\n"})}),"\n",(0,i.jsx)(n.h3,{id:"5-review-alert-logs",children:"5. Review Alert Logs"}),"\n",(0,i.jsxs)(n.p,{children:["Weekly review of ",(0,i.jsx)(n.code,{children:"data/logs/alerts.jsonl"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Are there false positives?"}),"\n",(0,i.jsx)(n.li,{children:"Are thresholds too sensitive?"}),"\n",(0,i.jsx)(n.li,{children:"Are any alerts never firing (maybe remove them)?"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"additional-resources",children:"Additional Resources"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Prometheus Alerting"}),": ",(0,i.jsx)(n.a,{href:"https://prometheus.io/docs/alerting/latest/overview/",children:"https://prometheus.io/docs/alerting/latest/overview/"})]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"AlertManager Configuration"}),": ",(0,i.jsx)(n.a,{href:"https://prometheus.io/docs/alerting/latest/configuration/",children:"https://prometheus.io/docs/alerting/latest/configuration/"})]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Alert Best Practices"}),": ",(0,i.jsx)(n.a,{href:"https://prometheus.io/docs/practices/alerting/",children:"https://prometheus.io/docs/practices/alerting/"})]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Grafana Alerts"}),": ",(0,i.jsx)(n.a,{href:"https://grafana.com/docs/grafana/latest/alerting/",children:"https://grafana.com/docs/grafana/latest/alerting/"})]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Last Updated"}),": October 2025"]})]})}function h(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>t,x:()=>a});var s=r(6540);const i={},l=s.createContext(i);function t(e){const n=s.useContext(l);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:t(e.components),s.createElement(l.Provider,{value:n},e.children)}}}]);